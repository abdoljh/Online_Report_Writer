import streamlit as st
import json
import requests
import time
from datetime import datetime
import base64
from typing import List, Dict, Any
import re

# Page configuration
st.set_page_config(
    page_title="Online Report Writer System",
    page_icon="üìù",
    layout="wide",
    initial_sidebar_state="collapsed"
)

# Custom CSS
st.markdown("""
<style>
    .stProgress > div > div > div > div {
        background-color: #4F46E5;
    }
    .css-1d391kg {
        padding-top: 1.5rem;
    }
    .report-stats {
        background-color: #F3F4F6;
        padding: 1rem;
        border-radius: 0.5rem;
        margin: 0.5rem 0;
    }
    .source-item {
        padding: 0.5rem;
        margin: 0.25rem 0;
        background-color: #F0F9FF;
        border-radius: 0.25rem;
        border-left: 3px solid #3B82F6;
    }
    .stButton > button {
        width: 100%;
    }
</style>
""", unsafe_allow_html=True)

# Initialize session state
if 'step' not in st.session_state:
    st.session_state.step = 'input'
if 'form_data' not in st.session_state:
    st.session_state.form_data = {
        'topic': '',
        'subject': '',
        'researcher': '',
        'institution': '',
        'date': datetime.now().strftime('%Y-%m-%d')
    }
if 'progress' not in st.session_state:
    st.session_state.progress = {
        'stage': '',
        'detail': '',
        'percent': 0
    }
if 'research' not in st.session_state:
    st.session_state.research = {
        'queries': [],
        'sources': [],
        'subtopics': []
    }
if 'draft' not in st.session_state:
    st.session_state.draft = None
if 'critique' not in st.session_state:
    st.session_state.critique = None
if 'final_report' not in st.session_state:
    st.session_state.final_report = None
if 'is_processing' not in st.session_state:
    st.session_state.is_processing = False
if 'api_call_count' not in st.session_state:
    st.session_state.api_call_count = 0
if 'last_api_call_time' not in st.session_state:
    st.session_state.last_api_call_time = 0

# Get API key from Streamlit secrets
try:
    ANTHROPIC_API_KEY = st.secrets["ANTHROPIC_API_KEY"]
    API_AVAILABLE = True
except (KeyError, FileNotFoundError):
    st.error("‚ö†Ô∏è Anthropic API key not found in secrets. Please add it to your Streamlit secrets.")
    API_AVAILABLE = False

def update_progress(stage: str, detail: str, percent: int):
    """Update progress in session state"""
    st.session_state.progress = {
        'stage': stage,
        'detail': detail,
        'percent': min(100, percent)
    }

def calculate_credibility(url: str) -> int:
    """Calculate credibility score based on domain"""
    url_lower = url.lower()
    if '.gov' in url_lower or '.edu' in url_lower:
        return 95
    if 'nature.com' in url_lower or 'science.org' in url_lower:
        return 95
    if 'ieee.org' in url_lower or 'acm.org' in url_lower:
        return 90
    if '.org' in url_lower:
        return 85
    return 80

def rate_limit_wait():
    """Implement rate limiting between API calls"""
    current_time = time.time()
    time_since_last_call = current_time - st.session_state.last_api_call_time
    
    # Wait at least 2 seconds between calls to avoid rate limiting
    min_wait_time = 2.0
    if time_since_last_call < min_wait_time:
        wait_time = min_wait_time - time_since_last_call
        time.sleep(wait_time)
    
    st.session_state.last_api_call_time = time.time()
    st.session_state.api_call_count += 1

def parse_json_response(text: str) -> Dict:
    """Parse JSON from AI response, handling code blocks"""
    try:
        # Remove markdown code blocks
        cleaned = re.sub(r'```json\n?|```\n?', '', text).strip()
        return json.loads(cleaned)
    except json.JSONDecodeError:
        # Try to extract JSON from text
        json_match = re.search(r'\{.*\}', text, re.DOTALL)
        if json_match:
            try:
                return json.loads(json_match.group())
            except:
                pass
        st.warning(f"Failed to parse JSON response. Using fallback data.")
        return {}

def call_anthropic_api(messages: List[Dict], max_tokens: int = 1000, use_web_search: bool = False) -> Dict:
    """Call Anthropic Claude API with rate limiting"""
    if not API_AVAILABLE:
        raise Exception("API key not configured")

    # Implement rate limiting
    rate_limit_wait()

    headers = {
        "Content-Type": "application/json",
        "x-api-key": ANTHROPIC_API_KEY,
        "anthropic-version": "2023-06-01"
    }

    data = {
        "model": "claude-sonnet-4-20250514",
        "max_tokens": max_tokens,
        "messages": messages
    }

    if use_web_search:
        data["tools"] = [{
            "type": "web_search_20250305",
            "name": "web_search"
        }]

    max_retries = 3
    for attempt in range(max_retries):
        try:
            response = requests.post(
                "https://api.anthropic.com/v1/messages",
                headers=headers,
                json=data,
                timeout=120
            )
            
            if response.status_code == 429:
                # Rate limited - wait longer
                wait_time = 10 * (attempt + 1)
                st.warning(f"Rate limited. Waiting {wait_time} seconds before retry {attempt + 1}/{max_retries}...")
                time.sleep(wait_time)
                continue
                
            response.raise_for_status()
            return response.json()
            
        except requests.exceptions.RequestException as e:
            if attempt == max_retries - 1:
                st.error(f"API call failed after {max_retries} attempts: {str(e)}")
                raise
            time.sleep(5 * (attempt + 1))

# Stage 1: Topic Analysis
def analyze_topic_with_ai(topic: str, subject: str) -> Dict:
    """Analyze topic and generate research structure"""
    update_progress('Topic Analysis', 'Decomposing topic into research dimensions...', 10)

    prompt = f"""Analyze this research topic and provide a structured breakdown:

Topic: "{topic}"
Subject: "{subject}"

Provide a JSON response with:
1. subtopics: Array of 5-7 specific subtopics to investigate
2. researchQueries: Array of 10 diverse search queries covering:
   - Academic/theoretical aspects
   - Current statistics and data
   - Policy and governance
   - Industry applications
   - Future trends
   - Challenges and limitations
   - Expert opinions

IMPORTANT: Return ONLY valid JSON, no other text.

Example format:
{{
  "subtopics": ["Subtopic 1", "Subtopic 2", "Subtopic 3"],
  "researchQueries": ["Query 1", "Query 2", "Query 3"]
}}"""

    try:
        response = call_anthropic_api([
            {
                "role": "user",
                "content": prompt
            }
        ], max_tokens=1500)

        if 'content' in response:
            text_content = ""
            for content in response['content']:
                if content['type'] == 'text':
                    text_content += content['text']

            result = parse_json_response(text_content)
            
            # Ensure we have the required keys
            if not result.get('subtopics'):
                result['subtopics'] = [
                    f"Core Concepts in {subject}",
                    f"Current State of {topic}",
                    f"Applications and Use Cases",
                    f"Challenges and Limitations",
                    f"Future Directions"
                ]
            
            if not result.get('researchQueries'):
                result['researchQueries'] = [
                    f"{topic} overview {subject}",
                    f"Latest developments in {topic}",
                    f"{topic} statistics and data",
                    f"{topic} applications",
                    f"Future of {topic}"
                ]
            
            return result
            
    except Exception as e:
        st.error(f"Topic analysis failed: {str(e)}")
        # Return fallback structure
        return {
            "subtopics": [
                f"Overview of {topic}",
                f"Current State and Statistics",
                f"Applications and Use Cases",
                f"Challenges and Limitations",
                f"Future Outlook"
            ],
            "researchQueries": [
                f"{topic} overview",
                f"{topic} latest research",
                f"{topic} statistics",
                f"{topic} applications",
                f"{topic} future trends"
            ]
        }

# Stage 2: Web Research with Better Error Handling
def execute_web_research(queries: List[str]) -> List[Dict]:
    """Execute web research with real API calls and proper rate limiting"""
    update_progress('Web Research', f'Executing {len(queries)} searches...', 25)
    
    sources = []
    trusted_domains = [
        '.edu', '.gov', '.org', 'nature.com', 'science.org', 'ieee.org',
        'acm.org', 'springer.com', 'wiley.com', 'who.int', 'worldbank.org',
        'oecd.org', 'nih.gov', 'nsf.gov', 'arxiv.org', 'pnas.org'
    ]

    # Limit to first 6 queries to avoid rate limiting
    limited_queries = queries[:6]
    
    for i, query in enumerate(limited_queries):
        progress = 25 + (i / len(limited_queries)) * 20
        update_progress('Web Research', f'Query {i + 1}/{len(limited_queries)}: {query[:50]}...', progress)

        try:
            # Use web search tool
            search_response = call_anthropic_api(
                messages=[{
                    "role": "user",
                    "content": f"Search for: {query}. Focus on academic sources from .edu, .gov, and reputable .org domains."
                }],
                max_tokens=1000,
                use_web_search=True
            )

            # Parse response for sources
            if 'content' in search_response:
                for content_block in search_response['content']:
                    if content_block.get('type') == 'text':
                        text = content_block.get('text', '')
                        
                        # Extract URLs from the text
                        urls = re.findall(r'https?://[^\s<>"{}|\\^`\[\]]+', text)
                        
                        for url in urls:
                            # Check if URL is from trusted domain
                            is_trusted = any(domain in url.lower() for domain in trusted_domains)
                            
                            if is_trusted:
                                # Extract context around the URL
                                url_pos = text.find(url)
                                context_start = max(0, url_pos - 300)
                                context_end = min(len(text), url_pos + 300)
                                context = text[context_start:context_end]
                                
                                # Try to find a title
                                sentences = context.split('.')
                                title = sentences[0][:100] if sentences else f"Source: {query[:50]}"
                                
                                sources.append({
                                    'title': title.strip(),
                                    'url': url,
                                    'content': context.strip()[:500],
                                    'query': query,
                                    'credibilityScore': calculate_credibility(url),
                                    'dateAccessed': datetime.now().isoformat()
                                })

        except Exception as error:
            st.warning(f"Search failed for: {query[:50]}... Error: {str(error)}")
            continue

    # Deduplicate sources by URL
    seen_urls = set()
    unique_sources = []
    for source in sources:
        if source['url'] not in seen_urls:
            seen_urls.add(source['url'])
            unique_sources.append(source)

    # If we got very few sources, add some high-quality generic sources
    if len(unique_sources) < 3:
        st.info("Limited sources found. Adding supplementary academic references...")
        generic_sources = [
            {
                "title": f"Academic Overview: {queries[0][:60]}",
                "url": "https://scholar.google.com/research",
                "content": f"Academic research and peer-reviewed literature on {queries[0]}. This encompasses theoretical frameworks, empirical studies, and scholarly discourse.",
                "query": queries[0],
                "credibilityScore": 90,
                "dateAccessed": datetime.now().isoformat()
            },
            {
                "title": f"Technical Documentation: {queries[1][:60] if len(queries) > 1 else queries[0][:60]}",
                "url": "https://www.researchgate.net/publication",
                "content": "Technical specifications, methodologies, and research findings from academic institutions and research organizations.",
                "query": queries[1] if len(queries) > 1 else queries[0],
                "credibilityScore": 85,
                "dateAccessed": datetime.now().isoformat()
            },
            {
                "title": f"Industry Analysis: Current State and Trends",
                "url": "https://www.rand.org/research",
                "content": "Comprehensive analysis of current developments, statistical data, and expert perspectives from research institutions.",
                "query": queries[0],
                "credibilityScore": 88,
                "dateAccessed": datetime.now().isoformat()
            }
        ]
        unique_sources.extend(generic_sources)

    return unique_sources

# Stage 3: Draft Generation
def generate_draft(topic: str, subject: str, subtopics: List[str], sources: List[Dict]) -> Dict:
    """Generate comprehensive research draft"""
    update_progress('Drafting', 'Synthesizing research into comprehensive report...', 50)

    source_summary = "\n\n".join([
        f"Source {i+1}: {s.get('title', 'Unknown')}\n"
        f"URL: {s.get('url', 'No URL')}\n"
        f"Key Points: {s.get('content', 'No content')[:400]}..."
        for i, s in enumerate(sources[:8])
    ])

    prompt = f"""Create a comprehensive academic research report on "{topic}" in {subject}.

Subtopics to cover: {', '.join(subtopics)}

Available Research Sources:
{source_summary}

Create a structured report with these sections:
1. Abstract (150-250 words)
2. Introduction (establishing context and importance)
3. Literature Review (synthesizing research sources)
4. Main Body (3-4 sections organized by subtopics)
5. Data & Statistical Analysis (if applicable)
6. Challenges & Limitations
7. Future Outlook
8. Conclusion

Requirements:
- Use formal academic tone
- Reference information appropriately
- Include specific insights from sources
- Maintain logical flow
- 2000-3000 words total

Return ONLY valid JSON with these exact keys:
{{
  "abstract": "text here",
  "introduction": "text here",
  "literatureReview": "text here",
  "mainSections": [
    {{"title": "Section Title", "content": "content here"}}
  ],
  "dataAnalysis": "text here",
  "challenges": "text here",
  "futureOutlook": "text here",
  "conclusion": "text here"
}}"""

    try:
        response = call_anthropic_api([
            {
                "role": "user",
                "content": prompt
            }
        ], max_tokens=4000)

        if 'content' in response:
            text_content = ""
            for content in response['content']:
                if content['type'] == 'text':
                    text_content += content['text']

            draft_data = parse_json_response(text_content)

            # Ensure all required keys exist
            required_keys = ['abstract', 'introduction', 'literatureReview', 'mainSections',
                            'dataAnalysis', 'challenges', 'futureOutlook', 'conclusion']
            for key in required_keys:
                if key not in draft_data or not draft_data[key]:
                    if key == 'mainSections':
                        draft_data[key] = [{'title': 'Main Analysis', 'content': 'Content generated from research sources.'}]
                    else:
                        draft_data[key] = f"This section covers {key.replace('_', ' ')} aspects of {topic}."

            return draft_data

    except Exception as e:
        st.error(f"Draft generation failed: {str(e)}")
        
    # Fallback draft structure
    return {
        'abstract': f'This report examines {topic} in the context of {subject}, analyzing current developments, challenges, and future directions.',
        'introduction': f'The field of {subject} has seen significant developments in {topic}. This report provides a comprehensive analysis based on current research and expert sources.',
        'literatureReview': 'A review of academic literature and authoritative sources reveals multiple perspectives and findings relevant to this topic.',
        'mainSections': [
            {'title': subtopics[0] if subtopics else 'Core Concepts', 'content': 'Analysis of fundamental concepts and principles.'},
            {'title': subtopics[1] if len(subtopics) > 1 else 'Current State', 'content': 'Examination of the current state and recent developments.'},
            {'title': subtopics[2] if len(subtopics) > 2 else 'Applications', 'content': 'Discussion of practical applications and use cases.'}
        ],
        'dataAnalysis': 'Statistical analysis and data-driven insights from authoritative sources.',
        'challenges': 'Current challenges and limitations identified in the research.',
        'futureOutlook': 'Projected future developments and potential directions for advancement.',
        'conclusion': f'This report has examined {topic} comprehensively, identifying key trends, challenges, and opportunities for future development.'
    }

# Stage 4: Critique
def critique_draft(draft: Dict, sources: List[Dict]) -> Dict:
    """Critique the draft for quality and accuracy"""
    update_progress('Review', 'Critical analysis by reviewer agent...', 70)

    prompt = f"""Review this academic report draft for quality:

Report Structure: {list(draft.keys())}
Number of sources: {len(sources)}

Perform these quality checks:
1. Does the content flow logically?
2. Are there any weak or unsupported areas?
3. Is the academic tone consistent?
4. Are sections well-balanced?
5. Overall quality assessment

Return ONLY valid JSON:
{{
  "factIssues": ["list of issues"],
  "flowIssues": ["list of issues"],
  "unsupportedClaims": ["list of claims"],
  "biasFlags": ["list of biases"],
  "structuralWeaknesses": ["list of weaknesses"],
  "citationIssues": ["list of issues"],
  "overallScore": 85,
  "recommendations": ["list of recommendations"]
}}"""

    try:
        response = call_anthropic_api([
            {
                "role": "user",
                "content": prompt
            }
        ], max_tokens=2000)

        if 'content' in response:
            text_content = ""
            for content in response['content']:
                if content['type'] == 'text':
                    text_content += content['text']

            critique_data = parse_json_response(text_content)

            # Ensure all required keys exist
            if 'overallScore' not in critique_data:
                critique_data['overallScore'] = 80
                
            for key in ['factIssues', 'flowIssues', 'unsupportedClaims', 'biasFlags',
                       'structuralWeaknesses', 'citationIssues', 'recommendations']:
                if key not in critique_data:
                    critique_data[key] = []

            return critique_data

    except Exception as e:
        st.warning(f"Critique generation had issues: {str(e)}")

    return {
        'factIssues': [],
        'flowIssues': [],
        'unsupportedClaims': [],
        'biasFlags': [],
        'structuralWeaknesses': [],
        'citationIssues': [],
        'overallScore': 80,
        'recommendations': ['Review completed with standard quality assessment']
    }

# Stage 5: Refine
def refine_draft(draft: Dict, critique: Dict, sources: List[Dict]) -> Dict:
    """Refine draft based on critique"""
    update_progress('Refinement', 'Applying editorial improvements...', 85)

    prompt = f"""Refine this academic report by:
1. Enhancing academic tone and clarity
2. Adding an executive summary (200 words)
3. Strengthening transitions between sections
4. Ensuring proper structure

Quality Score: {critique.get('overallScore', 'N/A')}
Recommendations: {', '.join(critique.get('recommendations', [])[:3])}

Return the complete refined report as JSON with all original keys PLUS executiveSummary.
Return ONLY valid JSON, no other text."""

    try:
        response = call_anthropic_api([
            {
                "role": "user",
                "content": prompt
            }
        ], max_tokens=4000)

        if 'content' in response:
            text_content = ""
            for content in response['content']:
                if content['type'] == 'text':
                    text_content += content['text']

            refined_data = parse_json_response(text_content)

            # Ensure executiveSummary exists
            if 'executiveSummary' not in refined_data:
                refined_data['executiveSummary'] = f"This comprehensive research report examines key aspects of the topic, drawing on {len(sources)} authoritative sources to provide insights, analysis, and recommendations."

            # Merge with original draft to ensure all fields present
            for key in draft:
                if key not in refined_data:
                    refined_data[key] = draft[key]

            return refined_data

    except Exception as e:
        st.warning(f"Refinement had issues: {str(e)}. Using original draft.")

    # Add executive summary to original draft
    draft['executiveSummary'] = f"This report provides comprehensive analysis and insights based on research from {len(sources)} authoritative sources, examining key developments, challenges, and future directions."
    return draft

def generate_html_report(refined_draft: Dict, form_data: Dict, sources: List[Dict]) -> str:
    """Generate HTML report for download"""
    update_progress('Report Generation', 'Creating professional document...', 95)

    # Format date
    try:
        report_date = datetime.strptime(form_data['date'], '%Y-%m-%d').strftime('%B %d, %Y')
    except:
        report_date = datetime.now().strftime('%B %d, %Y')

    # Build HTML content
    html_content = f"""<!DOCTYPE html>
<html>
<head>
    <meta charset="utf-8">
    <title>{form_data['topic']} - Research Report</title>
    <style>
        @page {{ margin: 1in; }}
        body {{
            font-family: 'Times New Roman', serif;
            font-size: 12pt;
            line-height: 1.6;
            color: #000;
            max-width: 8.5in;
            margin: 0 auto;
            padding: 0.5in;
        }}
        .cover {{
            text-align: center;
            padding-top: 2in;
            page-break-after: always;
        }}
        .cover h1 {{
            font-size: 24pt;
            font-weight: bold;
            margin: 1in 0 0.5in 0;
        }}
        .cover .meta {{
            font-size: 14pt;
            margin: 0.25in 0;
        }}
        h1 {{
            font-size: 18pt;
            margin-top: 0.5in;
            border-bottom: 2px solid #333;
            padding-bottom: 0.1in;
        }}
        h2 {{
            font-size: 14pt;
            margin-top: 0.3in;
            font-weight: bold;
        }}
        p {{
            text-align: justify;
            margin: 0.15in 0;
        }}
        .abstract {{
            font-style: italic;
            margin: 0.25in 0.5in;
        }}
        .references {{
            page-break-before: always;
        }}
        .ref-item {{
            margin: 0.15in 0 0.15in 0.5in;
            text-indent: -0.5in;
            padding-left: 0.5in;
        }}
    </style>
</head>
<body>
    <div class="cover">
        <h1>{form_data['topic']}</h1>
        <div class="meta">A Research Report</div>
        <div class="meta">Subject: {form_data['subject']}</div>
        <div class="meta" style="margin-top: 1in;">
            Prepared by<br>
            {form_data['researcher']}<br>
            {form_data['institution']}<br>
            {report_date}
        </div>
    </div>

    <h1>Executive Summary</h1>
    <p>{refined_draft.get('executiveSummary', 'Executive summary not available.')}</p>

    <h1>Abstract</h1>
    <div class="abstract">{refined_draft.get('abstract', 'Abstract not available.')}</div>

    <h1>Introduction</h1>
    <p>{refined_draft.get('introduction', 'Introduction not available.')}</p>

    <h1>Literature Review</h1>
    <p>{refined_draft.get('literatureReview', 'Literature review not available.')}</p>
"""

    # Add main sections
    for section in refined_draft.get('mainSections', []):
        html_content += f"""
    <h2>{section.get('title', 'Section Title')}</h2>
    <p>{section.get('content', 'Content not available.')}</p>
"""

    # Add remaining sections
    html_content += f"""
    <h1>Data & Statistical Analysis</h1>
    <p>{refined_draft.get('dataAnalysis', 'Data analysis not available.')}</p>

    <h1>Challenges and Limitations</h1>
    <p>{refined_draft.get('challenges', 'Challenges not available.')}</p>

    <h1>Future Outlook</h1>
    <p>{refined_draft.get('futureOutlook', 'Future outlook not available.')}</p>

    <h1>Conclusion</h1>
    <p>{refined_draft.get('conclusion', 'Conclusion not available.')}</p>

    <div class="references">
        <h1>References</h1>
"""

    # Add references
    for i, source in enumerate(sources, 1):
        try:
            source_date = datetime.fromisoformat(source['dateAccessed'].replace('Z', '+00:00')).strftime('%B %d, %Y')
        except:
            source_date = datetime.now().strftime('%B %d, %Y')

        html_content += f"""
        <div class="ref-item">
            [{i}] {source.get('title', 'Unknown Title')}. Retrieved from {source.get('url', 'No URL')} (Accessed: {source_date})
        </div>
"""

    html_content += """
    </div>
</body>
</html>"""

    return html_content

def execute_research_pipeline():
    """Main execution pipeline with proper error handling"""
    st.session_state.is_processing = True
    st.session_state.step = 'processing'
    st.session_state.api_call_count = 0

    try:
        if not API_AVAILABLE:
            raise Exception("Anthropic API key not configured in Streamlit secrets.")

        # Stage 1: Topic Analysis
        st.info("üîç Stage 1: Analyzing topic and generating research structure...")
        analysis = analyze_topic_with_ai(
            st.session_state.form_data['topic'],
            st.session_state.form_data['subject']
        )

        st.session_state.research = {
            'subtopics': analysis['subtopics'],
            'queries': analysis['researchQueries'],
            'sources': []
        }

        # Stage 2: Web Research
        st.info("üåê Stage 2: Conducting web research (this may take a few minutes)...")
        sources = execute_web_research(analysis['researchQueries'])
        st.session_state.research['sources'] = sources

        if len(sources) < 2:
            st.warning(f"Found only {len(sources)} sources. Report quality may be limited.")

        # Stage 3: Draft
        st.info("‚úçÔ∏è Stage 3: Generating initial draft...")
        draft_content = generate_draft(
            st.session_state.form_data['topic'],
            st.session_state.form_data['subject'],
            analysis['subtopics'],
            sources
        )
        st.session_state.draft = draft_content

        # Stage 4: Critique
        st.info("üîç Stage 4: Reviewing draft quality...")
        critique_content = critique_draft(draft_content, sources)
        st.session_state.critique = critique_content

        # Stage 5: Refine
        st.info("‚ú® Stage 5: Refining and polishing report...")
        refined_content = refine_draft(draft_content, critique_content, sources)
        st.session_state.final_report = refined_content

        # Stage 6: Generate Report
        st.info("üìÑ Stage 6: Generating final HTML report...")
        html_report = generate_html_report(
            refined_content,
            st.session_state.form_data,
            sources
        )

        update_progress("Complete", "Report generated successfully!", 100)
        st.session_state.html_report = html_report
        st.session_state.step = 'complete'
        
        st.success(f"‚úÖ Report complete! Made {st.session_state.api_call_count} API calls total.")

    except Exception as e:
        update_progress("Error", str(e), 0)
        st.session_state.step = 'error'
        st.error(f"‚ùå Pipeline error: {str(e)}")
    finally:
        st.session_state.is_processing = False

def reset_system():
    """Reset the system to initial state"""
    st.session_state.step = 'input'
    st.session_state.form_data = {
        'topic': '',
        'subject': '',
        'researcher': '',
        'institution': '',
        'date': datetime.now().strftime('%Y-%m-%d')
    }
    st.session_state.progress = {
        'stage': '',
        'detail': '',
        'percent': 0
    }
    st.session_state.research = {
        'queries': [],
        'sources': [],
        'subtopics': []
    }
    st.session_state.draft = None
    st.session_state.critique = None
    st.session_state.final_report = None
    st.session_state.is_processing = False
    st.session_state.api_call_count = 0
    if 'html_report' in st.session_state:
        del st.session_state.html_report

# Main UI
st.title("üìù Online Report Writer System")
st.markdown("**AI-Powered Academic Research Report Generator**")

if st.session_state.step == 'input':
    st.markdown("### Research Report Configuration")
    st.markdown("Fill in the details below to generate a comprehensive research report.")

    col1, col2 = st.columns(2)

    with col1:
        topic = st.text_input(
            "Report Topic *",
            value=st.session_state.form_data['topic'],
            placeholder="e.g., Artificial Intelligence in Healthcare",
            help="Enter the main topic for your research report"
        )
        subject = st.text_input(
            "Subject / Field *",
            value=st.session_state.form_data['subject'],
            placeholder="e.g., Computer Science, Medicine, Engineering",
            help="Enter the academic or professional field"
        )

    with col2:
        researcher = st.text_input(
            "Researcher Name *",
            value=st.session_state.form_data['researcher'],
            placeholder="Your name",
            help="Enter your name or the researcher's name"
        )
        institution = st.text_input(
            "Institution *",
            value=st.session_state.form_data['institution'],
            placeholder="University or Organization",
            help="Enter your institution or organization"
        )

    date = st.date_input(
        "Report Date",
        value=datetime.strptime(st.session_state.form_data['date'], '%Y-%m-%d'),
        help="Select the date for the report"
    )

    # Update form data
    st.session_state.form_data = {
        'topic': topic,
        'subject': subject,
        'researcher': researcher,
        'institution': institution,
        'date': date.strftime('%Y-%m-%d')
    }

    is_form_valid = all([topic, subject, researcher, institution])

    st.markdown("---")
    
    col_info, col_button = st.columns([2, 1])
    with col_info:
        st.info("‚è±Ô∏è **Estimated time:** 3-5 minutes\n\nüìä **Process:** Topic Analysis ‚Üí Web Research ‚Üí Draft ‚Üí Review ‚Üí Refine ‚Üí Generate")
    
    with col_button:
        if st.button(
            "üöÄ Generate Report",
            disabled=not is_form_valid or not API_AVAILABLE,
            type="primary",
            use_container_width=True
        ):
            execute_research_pipeline()
            st.rerun()
    
    if not is_form_valid:
        st.warning("‚ö†Ô∏è Please fill in all required fields (*)")
    
    if not API_AVAILABLE:
        st.error("‚ö†Ô∏è API key not configured. Please add ANTHROPIC_API_KEY to Streamlit secrets.")

elif st.session_state.step == 'processing':
    st.markdown("### üîÑ Research in Progress")
    
    # Create a placeholder for dynamic updates
    progress_placeholder = st.empty()
    
    with progress_placeholder.container():
        # Progress bar
        col1, col2 = st.columns([4, 1])
        with col1:
            st.markdown(f"**{st.session_state.progress['stage']}**")
            st.progress(st.session_state.progress['percent'] / 100)
        with col2:
            st.metric("Progress", f"{st.session_state.progress['percent']}%")

        st.info(f"‚ÑπÔ∏è {st.session_state.progress['detail']}")
        
        if st.session_state.api_call_count > 0:
            st.caption(f"API Calls Made: {st.session_state.api_call_count}")

    # Research details in expandable sections
    if st.session_state.research['queries']:
        with st.expander(f"üìã Research Queries ({len(st.session_state.research['queries'])})", expanded=False):
            for i, query in enumerate(st.session_state.research['queries'], 1):
                st.markdown(f"**{i}.** {query}")

    if st.session_state.research['subtopics']:
        with st.expander(f"üìö Subtopics ({len(st.session_state.research['subtopics'])})", expanded=False):
            for i, subtopic in enumerate(st.session_state.research['subtopics'], 1):
                st.markdown(f"**{i}.** {subtopic}")

    if st.session_state.research['sources']:
        with st.expander(f"üîç Sources Found ({len(st.session_state.research['sources'])})", expanded=True):
            for i, source in enumerate(st.session_state.research['sources'], 1):
                st.markdown(f"""
                <div class="source-item">
                    <strong>{i}. {source.get('title', 'Untitled')[:80]}</strong><br>
                    <small>üîó <a href="{source.get('url', '#')}" target="_blank">{source.get('url', 'No URL')[:60]}</a></small><br>
                    <small>üìä Credibility: {source.get('credibilityScore', 0)}%</small>
                </div>
                """, unsafe_allow_html=True)

    # Auto-refresh while processing
    if st.session_state.is_processing:
        time.sleep(2)
        st.rerun()

elif st.session_state.step == 'complete':
    st.success("‚úÖ Report Generated Successfully!")
    
    # Report details
    st.markdown("### üìã Report Details")
    col1, col2, col3 = st.columns(3)

    with col1:
        st.markdown("**üìù Topic**")
        st.info(st.session_state.form_data['topic'])
    with col2:
        st.markdown("**üéì Subject**")
        st.info(st.session_state.form_data['subject'])
    with col3:
        st.markdown("**üë§ Researcher**")
        st.info(st.session_state.form_data['researcher'])

    # Research statistics
    st.markdown("### üìä Research Statistics")
    stat_col1, stat_col2, stat_col3, stat_col4 = st.columns(4)

    with stat_col1:
        st.metric("Queries Executed", len(st.session_state.research['queries']))
    with stat_col2:
        st.metric("Sources Found", len(st.session_state.research['sources']))
    with stat_col3:
        if st.session_state.research['sources']:
            avg_quality = sum(s.get('credibilityScore', 0) for s in st.session_state.research['sources']) / len(st.session_state.research['sources'])
            st.metric("Avg Quality", f"{avg_quality:.0f}%")
        else:
            st.metric("Avg Quality", "N/A")
    with stat_col4:
        if st.session_state.critique:
            score = st.session_state.critique.get('overallScore', 'N/A')
            st.metric("Quality Score", f"{score}/100" if score != 'N/A' else "N/A")
        else:
            st.metric("Quality Score", "N/A")

    st.markdown("---")

    # Report preview
    st.markdown("### üìÑ Report Preview")

    if st.session_state.final_report:
        with st.expander("üìã Executive Summary", expanded=True):
            st.write(st.session_state.final_report.get('executiveSummary', 'Executive summary not available'))

        with st.expander("üîç Abstract", expanded=False):
            st.write(st.session_state.final_report.get('abstract', 'Abstract not available'))

        with st.expander("üìñ Introduction", expanded=False):
            st.write(st.session_state.final_report.get('introduction', 'Introduction not available'))

        if st.session_state.final_report.get('mainSections'):
            with st.expander("üìë Main Sections", expanded=False):
                for section in st.session_state.final_report['mainSections']:
                    st.subheader(section.get('title', 'Untitled Section'))
                    st.write(section.get('content', 'Content not available'))

        with st.expander("üéØ Conclusion", expanded=False):
            st.write(st.session_state.final_report.get('conclusion', 'Conclusion not available'))

    # Sources used
    if st.session_state.research['sources']:
        with st.expander(f"üìö References ({len(st.session_state.research['sources'])})", expanded=False):
            for i, source in enumerate(st.session_state.research['sources'], 1):
                st.markdown(f"""
                **[{i}]** {source.get('title', 'Unknown Title')}  
                üîó [{source.get('url', 'No URL')}]({source.get('url', '#')})  
                üìä Credibility Score: {source.get('credibilityScore', 0)}%  
                üìÖ Accessed: {source.get('dateAccessed', 'Unknown')[:10]}
                """)

    # Quality feedback
    if st.session_state.critique:
        with st.expander("‚úÖ Quality Review Feedback", expanded=False):
            col1, col2 = st.columns(2)
            with col1:
                st.metric("Overall Score", f"{st.session_state.critique.get('overallScore', 'N/A')}/100")
            with col2:
                st.metric("API Calls", st.session_state.api_call_count)

            if st.session_state.critique.get('recommendations'):
                st.markdown("**üìù Recommendations:**")
                for rec in st.session_state.critique['recommendations']:
                    st.markdown(f"‚Ä¢ {rec}")

    st.markdown("---")

    # Download report
    st.markdown("### üì• Download Report")

    if 'html_report' in st.session_state:
        col1, col2 = st.columns([2, 1])
        
        with col1:
            # Create download button for HTML
            b64 = base64.b64encode(st.session_state.html_report.encode()).decode()
            filename = f"{st.session_state.form_data['topic'].replace(' ', '_')}_Research_Report.html"
            
            st.download_button(
                label="üì• Download HTML Report",
                data=st.session_state.html_report,
                file_name=filename,
                mime="text/html",
                type="primary",
                use_container_width=True
            )
        
        with col2:
            st.metric("File Size", f"{len(st.session_state.html_report) / 1024:.1f} KB")

        st.info("""
        **üìã How to Create PDF:**
        1. Click "Download HTML Report" above
        2. Open the downloaded file in any web browser
        3. Press `Ctrl+P` (Windows) or `Cmd+P` (Mac)
        4. Select "Save as PDF" as the destination
        5. Click "Save" to create your professional PDF report
        
        **üí° Tips:**
        - Adjust margins for optimal layout
        - Enable "Background graphics" for better appearance
        - Use "Print" settings to customize page size
        """)

    st.markdown("---")

    # Generate another report
    col1, col2, col3 = st.columns([1, 2, 1])
    with col2:
        if st.button("üîÑ Generate Another Report", use_container_width=True, type="secondary"):
            reset_system()
            st.rerun()

elif st.session_state.step == 'error':
    st.error("‚ùå Error Occurred During Report Generation")

    st.warning(st.session_state.progress['detail'])
    
    st.markdown("### üîß Troubleshooting")
    st.markdown("""
    **Common Issues:**
    - **Rate Limiting:** The API has usage limits. Wait a few minutes and try again.
    - **API Key:** Ensure your Anthropic API key is correctly configured in Streamlit secrets.
    - **Network Issues:** Check your internet connection.
    - **Topic Complexity:** Try a more specific or different topic.
    
    **Tips:**
    - Use clear, specific topic names
    - Ensure the subject field is filled correctly
    - Wait 2-3 minutes between generating reports
    """)

    col1, col2, col3 = st.columns([1, 2, 1])
    with col2:
        if st.button("üîÑ Try Again", use_container_width=True, type="primary"):
            reset_system()
            st.rerun()

# Footer
st.markdown("---")
st.markdown("""
<div style="text-align: center; color: #666;">
    <p><strong>üî¨ Autonomous Research Pipeline</strong></p>
    <p style="font-size: 0.9em;">
        Topic Analysis ‚Üí Web Research ‚Üí Draft Generation ‚Üí Quality Review ‚Üí Refinement ‚Üí Report
    </p>
    <p style="font-size: 0.8em; margin-top: 1em;">
        Powered by Anthropic Claude API ‚Ä¢ AI-Assisted Research & Analysis<br>
        All sources are from trusted academic and authoritative domains
    </p>
</div>
""", unsafe_allow_html=True)
